{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import glob2\n",
    "import pathlib\n",
    "import re\n",
    "import pyperclip\n",
    "import email\n",
    "from datetime import date, timedelta\n",
    "import winsound"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset, creating a list of employee emails for future reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_names = [\n",
    "    \"Phillip Allen\", \"John Arnold\", \"harry.arora\", \"Robert Badeer\", \"Susan Bailey\", \"Eric Bass\", \"Don Baughman\",\n",
    "    \"Sally Beck\", \"Robert Benson\", \"Lynn Blair\", \"Sandra Brawner\", \"Rick Buy\", \"Larry Campbell\", \"Mike Carson\",\n",
    "    \"Michelle Cash\", \"Monika Causholli\", \"Shelley Corman\", \"Sean Crandall\", \"Martin Cuilla\", \"jeff_dasovich\",\n",
    "    \"Dana Davis\", \"Craig Dean\", \"David Delainey\", \"James Derrick\", \"Stacy Dickson\", \"Lindy Donoho\", \"Tom Donohoe\",\n",
    "    \"Chris Dorland\", \"Frank Ermis\", \"Daren Farmer\", \"Mary Fischer\", \"John Forney\", \"Drew Fossum\", \"Lisa Gang\",\n",
    "    \"Randall Gay\", \"Tracy Geaccone\", \"Chris Germany\", \"doug.gilbert-smith\", \"Darron Giron\", \"john.griffith\",\n",
    "    \"mike.grigsby\", \"Mark Guzman\", \"Mark Haedicke\", \"Mary Hain\", \"Steven Harris\", \"Rod Hayslett\", \"Marie Heard\",\n",
    "    \"Scott Hendrickson\", \"Juan Hernandez\", \"John Hodge\", \"Keith Holst\", \"Stanley Horton\", \"Kevin Hyatt\", \"Dan Hyvl\",\n",
    "    \"Tana Jones\", \"Vince Kaminski\", \"Steven Kean\", \"Peter Keavey\", \"Kam Keiser\", \"Jeff King\", \"Louise Kitchen\",\n",
    "    \"Tori Kuykendall\", \"John Lavorato\", \"Kenneth Lay\", \"Matthew Lenhart\", \"Andrew Lewis\", \"Eric Linder\",\n",
    "    \"Michelle Lokay\", \"Teb Lokey\", \"Phillip Love\", \"Paul Lucci\", \"mike.maggi\", \"Kay Mann\", \"Thomas Martin\", \"larry.may\",\n",
    "    \"Danny McCarty\", \"Mike McConnell\", \"brad.mckay\", \"Jonathan Mckay\", \"Errol McLaughlin\", \"steven.merris\",\n",
    "    \"Albert Meyers\", \"l..mims\", \"matt.motley\", \"Scott Neal\", \"Gerald Nemec\", \"Stephanie Panus\", \"Joe Parks\",\n",
    "    \"Susan Pereira\", \"Debra Perlingiere\", \"Vladi Pimenov\", \"Phillip Platter\", \"Kevin Presto\", \"Joe Quenet\",\n",
    "    \"Dutch Quigley\", \"Bill Rapp\", \"Jay Reitmeyer\", \"Cooper Richey\", \"Andrea Ring\", \"Richard Ring\", \"Robin Rodrigue\",\n",
    "    \"Benjamin Rogers\", \"Kevin Ruscitti\", \"Elizabeth Sager\", \"Eric Saibi\", \"Holden Salisbury\", \"Monique Sanchez\",\n",
    "    \"Richard Sanders\", \"Diana Scholtes\", \"Darrell Schoolcraft\", \"Jim Schwieger\", \"Susan Scott\", \"Cara Semperger\",\n",
    "    \"Sara Shackleton\", \"Jeffrey Shankman\", \"Richard Shapiro\", \"Hunter Shively\", \"jeff.skilling\", \"Ryan Slinger\",\n",
    "    \"Matt Smith\", \"Geir Solberg\", \"steven.south\", \"Theresa Staab\", \"Carol Clair\", \"James Steffes\", \"Joe Stepenovitch\",\n",
    "    \"Chris Stokley\", \"geoff.storey\", \"Fletcher Sturm\", \"Mike Swerzbin\", \"Kate Symes\", \"Mark Taylor\", \"Jane Tholt\",\n",
    "    \"Paul Thomas\", \"Judy Townsend\", \"Barry Tycholiz\", \"Kim Ward\", \"Kimberly Watson\", \"Charles Weldon\", \"Greg.Whalley\",\n",
    "    \"Stacey White\", \"Mark Whitt\", \"Jason Williams\", \"bill.williams\", \"Jason Wolfe\", \"Paul Y'Barbo\", \"Andy Zipper\",\n",
    "    \"John Zufferli\"\n",
    "]\n",
    "\n",
    "employee_emails = [x.lower().replace(\" \", \".\") + \"@enron.com\" for x in employee_names]\n",
    "ds = pd.read_csv(\"./dataset.csv\")\n",
    "pattern = \"|\".join(employee_emails)\n",
    "\n",
    "# Filtering dataframe to only contain\n",
    "# emails that are sent by any of the employees\n",
    "ds = ds[ds[\"from\"].str.contains(pattern)]\n",
    "ds[\"date\"] = pd.to_datetime(ds[\"date\"])\n",
    "# min_date = ds[\"date\"].min()\n",
    "# min_date = ds[\"date\"].min()\n",
    "min_date = pd.to_datetime(\"2000-01-01\")\n",
    "max_date = ds[\"date\"].max()\n",
    "start_week = min_date.date()\n",
    "next_two_week = start_week + timedelta(weeks=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "tag1"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2000-01-01 00:00:00'), Timestamp('2002-06-25 00:00:00'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_date,max_date"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcitions for sliding time window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_two_weeks(start_week, next_two_week):\n",
    "    start_week = next_two_week\n",
    "    next_two_week = next_two_week + timedelta(weeks=2)\n",
    "    return start_week, next_two_week\n",
    "\n",
    "\n",
    "def reset_weeks(start_week, next_two_week):\n",
    "    start_week = min_date.date()\n",
    "    next_two_week = start_week + timedelta(weeks=2)\n",
    "    return start_week, next_two_week\n",
    "\n",
    "\n",
    "def merge_lists(first_list, second_list):\n",
    "    in_first = set(first_list)\n",
    "    in_second = set(second_list)\n",
    "    in_second_but_not_in_first = in_second - in_first\n",
    "    result = first_list + list(in_second_but_not_in_first)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def save_as_csv_and_npy(dataframe, path, filename):\n",
    "    dataframe.to_csv(path + filename)\n",
    "    t = dataframe.to_numpy()\n",
    "    filename = filename.replace(\".csv\", \".npy\")\n",
    "    with open(path + filename, 'wb') as f:\n",
    "        np.save(f, t)\n",
    "\n",
    "\n",
    "\n",
    "def play_sound():\n",
    "    duration = 300  # milliseconds\n",
    "    freq = 440  # Hz\n",
    "    winsound.Beep(freq, duration)\n",
    "    winsound.Beep(freq, duration)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk dataset into periods of two weeks and save them as `.csv` locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alireza Vaezi\\AppData\\Local\\Temp\\ipykernel_18104\\3114955561.py:3: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  while start_week < max_date:\n"
     ]
    }
   ],
   "source": [
    "start_week, next_two_week = reset_weeks(start_week, next_two_week)\n",
    "count = 0\n",
    "while start_week < max_date:\n",
    "    # print(count)\n",
    "    # print(start_week, next_two_week)\n",
    "    ss = ds[(ds[\"date\"] >= pd.to_datetime(start_week)) & (ds[\"date\"] < pd.to_datetime(next_two_week))]\n",
    "    start_week, next_two_week = move_two_weeks(start_week, next_two_week)\n",
    "    if ss.count()[\"id\"] > 0:\n",
    "        ss.to_csv(f\"./out/period-0000{count}.csv\")\n",
    "    count += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading each period, making adj-matrix for each, and saving locally as numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_directory = \"./out/*.csv\"\n",
    "\n",
    "all_paths = glob.glob(chunk_directory)\n",
    "period = pd.DataFrame(columns=['id', 'date', 'from', 'to', 'cc', 'bcc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in enumerate(all_paths):\n",
    "    filename = k.split(\"\\\\\")[1]\n",
    "\n",
    "    # location to save from_to\n",
    "    to_path = \"./adj_matrices_from_to/\"\n",
    "    # location to save cc_bcc\n",
    "    ccbcc_path = \"./adj_matrices_from_cc_bcc/\"\n",
    "    filename = filename.split(\".\")[0] + \"-adj_matrix.\" + filename.split(\".\")[1]\n",
    "\n",
    "    df = pd.read_csv(k)\n",
    "    to_adj_matrix = np.zeros((148, 148), dtype=int)\n",
    "    cc_bcc_adj_matrix = np.zeros((148, 148), dtype=int)\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            from_index = employee_emails.index(row['from'])\n",
    "        except Exception as e:\n",
    "            print(e, k)\n",
    "        if not from_index:\n",
    "            continue\n",
    "\n",
    "        # List of all email addresses used in TO field\n",
    "        to_list = row['to'].split(',') if pd.notna(row['to']) else []\n",
    "        cc_list = row['cc'].split(',') if pd.notna(row['cc']) else []\n",
    "        bcc_list = row['bcc'].split(',') if pd.notna(row['bcc']) else []\n",
    "\n",
    "        # List of all email addresses used in CC or BCC fields\n",
    "        all_cc_bcc = merge_lists(cc_list, bcc_list)\n",
    "\n",
    "        # An empty adj matrix\n",
    "        \n",
    "        for to in to_list:\n",
    "            if to in employee_emails:\n",
    "                to_index = employee_emails.index(to)\n",
    "                if to_index != from_index:\n",
    "                    to_adj_matrix[from_index, to_index] += 1\n",
    "                    to_adj_matrix[to_index, from_index] += 1\n",
    "        to_adj_matrix_df = pd.DataFrame(to_adj_matrix, columns=employee_emails, index=employee_emails)\n",
    "\n",
    "        # An empty adj matrix\n",
    "        for cc in all_cc_bcc:\n",
    "            if cc in employee_emails:\n",
    "                cc_bcc_index = employee_emails.index(cc)\n",
    "                if from_index != cc_bcc_index:\n",
    "                    cc_bcc_adj_matrix[from_index, cc_bcc_index] += 1\n",
    "                    cc_bcc_adj_matrix[cc_bcc_index, from_index] += 1\n",
    "        cc_bcc_adj_matrix_df = pd.DataFrame(cc_bcc_adj_matrix, columns=employee_emails, index=employee_emails)\n",
    "\n",
    "    save_as_csv_and_npy(to_adj_matrix_df, to_path, filename)\n",
    "    save_as_csv_and_npy(cc_bcc_adj_matrix_df, ccbcc_path, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_sound()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
